package agent;

import java.util.ArrayList;
import java.util.List;

import control.Constants;
import control.SeededRandom;
import landscape.FitnessFunction;

/**
 * The Agent class represents the agents that navigate the landscape. They use
 * their developmental program and blocks to construct their developmental strategy,
 * then execute their developmental strategy by incrementally making changes to their
 * phenotype.
 * 
 * This implementation uses the NKPhenotype for use on NK landscapes.
 * 
 * @author Jacob Ashworth
 *
 */
public class Agent implements Comparable<Agent> {
	//Fields related to evolutionary past
	private Agent parent = null;
	
	//Fields related to developmental strategy
	private List<Integer> program;
	private List<List<Step>> blocks;
	
	//These fields are generated by compileStrategy()
	private List<Step> strategy;
	/* This integer tracks the next step to run, so currentStep=0 means
	 * step 0 has not yet been executed. */
	private int currentStep = 0;
	 
	//Fields related to phenotype.
	private Phenotype phenotype;
	/* phenotypeHistory is indexed by step number, so phenotypeHistory.get(4)
	 * would give you the phenotype immediately before step 4 was executed */
	private List<Phenotype> phenotypeHistory = new ArrayList<Phenotype>();
	
	//Fields related to fitness
	private FitnessFunction fitnessFunction;
	public double fitness;
	//fitnessHistory is indexed the same as phenotypeHistory
	private List<Double> fitnessHistory = new ArrayList<Double>();
	
	/**
	 * Default constructor for Agent. Creates an agent with a random initial phenotype,
	 * program, and blocks.
	 * 
	 * @param fitnessFunction FitnessFunction for the agent to operate on
	 */
	public Agent(FitnessFunction fitnessFunction)
	{
		this.phenotype = new NKPhenotype();
		this.fitnessFunction = fitnessFunction;
		this.fitness = fitnessFunction.getFitness(phenotype); 
		
		//Create a random program
		program = new ArrayList<Integer>();
		for(int programIndex=0; programIndex < Constants.PROGRAM_LENGTH; programIndex++)
		{
			program.add(SeededRandom.getInstance().nextInt(Constants.NUMBER_OF_BLOCKS));
		}
		//Create random blocks
		blocks = new ArrayList<List<Step>>();
		for(int block=0; block < Constants.NUMBER_OF_BLOCKS; block++)
		{
			List<Step> thisBlock = new ArrayList<Step>();
			for(int stepIndex=0; stepIndex < Constants.BLOCK_LENGTH; stepIndex++)
			{
				thisBlock.add(Step.randomStep());
			}
			blocks.add(thisBlock);
		}
		//Compile the program and blocks into the strategy
		this.compileStrategy();
	}
	
	/**
	 * Constructor used to exactly specify an agent, with all relevant fields. 
	 * Mostly called by the identicalChild() function.
	 */
	public Agent(FitnessFunction fitnessFunction, Phenotype phenotype, List<Integer> program, List<List<Step>> blocks, Agent parent)
	{
		this.phenotype = phenotype;
		this.fitnessFunction = fitnessFunction;
		this.fitness = fitnessFunction.getFitness(phenotype);
		this.program = program;
		this.blocks = blocks;
		this.parent = parent;
		//Compile the program and blocks into the strategy
		this.compileStrategy();
	}
	
	/**
	 * This method compiles the developmental strategy from the program and
	 * the blocks by concatenating copies of the blocks specified in the order
	 * of the program
	 */
	private void compileStrategy()
	{
		strategy = new ArrayList<Step>();
		for(Integer blockIndex : program)
		{
			List<Step> block = blocks.get(blockIndex);
			strategy.addAll(block);
		}
	}
	
	/**
	 * Method to check if the agent has executed all steps in its developmental strategy
	 * @return
	 */
	public boolean agentDeveloped()
	{
		return currentStep == strategy.size();
	}
	
	/**
	 * Executes the current step of the developmental strategy
	 */
	public void executeSingleStep()
	{
		if(currentStep == 0)
		{
			//Enter our initial history record
			this.phenotypeHistory.add(phenotype);
			this.fitnessHistory.add(fitness);
		}
		//Get the step to execute and increment step counter
		Step stepToExecute = strategy.get(currentStep);
		currentStep++;
		
		//This is the main switch statement that controls which step is executed
		//When adding new steps, create a new step function and enum in Step, and add
		//it to the switch statement.
		switch(stepToExecute) {
			case RandomWalk:
				randomWalk();
			case SteepestClimb:
				steepestClimb();
			case SteepestFall:
				steepestFall();
		}
		
		//update the agent's fitness value
		fitness = fitnessFunction.getFitness(phenotype);
		
		//Store information
		phenotypeHistory.add(phenotype);
		fitnessHistory.add(fitness);
	}
	
	/**
	 * Executes the entire developmental strategy
	 * 
	 * If strategyExecutionSampleSize>1, this method will
	 * execute the entire strategy many times, but will delete
	 * the contents of pastPhenotypes since tracking past phenotype
	 * with a sample size greater than 1 isn't helpful
	 */
	public void executeStrategy()
	{
		if(Constants.STRATEGY_SAMPLE_SIZE == 1)
		{
			while(!agentDeveloped())
			{
				executeSingleStep();
			}
		}
		else
		{
			//Set up somewhere to average our fitness information
			Double[] summedFitnesses = new Double[strategy.size()];
			//Run our strategy STRATEGY_SAMPLE_SIZE times, and sum the results
			for(int sample=0; sample<Constants.STRATEGY_SAMPLE_SIZE; sample++)
			{
				//Wipe all information and reset agent to initial configuration
				currentStep = 0;
				phenotype = phenotypeHistory.get(0);
				phenotypeHistory.clear();
				phenotypeHistory.add(phenotype);
				fitness = fitnessHistory.get(0);
				fitnessHistory.clear();
				fitnessHistory.add(fitness);
				//Run the strategy
				while(!agentDeveloped())
				{
					executeSingleStep();
				}
				//Store fitness information
				for(int stepIndex = 0; stepIndex < strategy.size(); stepIndex++)
				{
					summedFitnesses[stepIndex]=summedFitnesses[stepIndex] + fitnessHistory.get(stepIndex);
				}
			}
			//Now store the average fitness at each step in the pastFitnesses list
			fitnessHistory.clear();
			for(int stepIndex = 0; stepIndex < strategy.size(); stepIndex++)
			{
				fitnessHistory.add(summedFitnesses[stepIndex] / (double) Constants.STRATEGY_SAMPLE_SIZE);
			}
		}
	}
	
	/**
	 * Makes an identical copy of the agent, except that this is a child
	 * of the current agent, so its parent is set accordingly
	 * 
	 * The child is setup under its initial configuration, so even if the
	 * parent's strategy has been run, the child's strategy will not yet
	 * be run
	 * 
	 * @return child that is identical to the parent
	 */
	public Agent identicalChild()
	{
		//We need to make a copy of each list to ensure the object references aren't passed
		List<Integer> childProgram = new ArrayList<Integer>();
		for(Integer i : program)
		{
			childProgram.add(i);
		}
		
		List<List<Step>> childBlocks = new ArrayList<List<Step>>();
		for(int block=0; block < blocks.size(); block++)
		{
			List<Step> childBlock = new ArrayList<Step>();
			for(Step s : blocks.get(block))
			{
				childBlock.add(s);
			}
			childBlocks.add(childBlock);
		}
		
		Phenotype childPhenotype = phenotype.getIdenticalCopy();
		
		//Use the constructor to make the new agent, and return it
		return new Agent(fitnessFunction, childPhenotype, childProgram, childBlocks, this);
	}
	
	/**
	 * Mutates the agent, using config specified mutation rates to make changes
	 * to the program, blocks, and phenotype
	 */
	public void mutate()
	{
		//phenotype mutation
		phenotype.mutate();
		
		//program mutation
		for(int programIndex=0; programIndex < Constants.PROGRAM_LENGTH; programIndex++)
		{
			if(SeededRandom.getInstance().nextDouble() < Constants.PROGRAM_MUTATION_RATE)
			{
				//Convinent way to use % operator to ensure we don't randomly roll the same block
				int programChangeAmount = SeededRandom.getInstance().nextInt(Constants.NUMBER_OF_BLOCKS-1);
				program.set(programIndex, (program.get(programIndex) + programChangeAmount) % Constants.NUMBER_OF_BLOCKS);
			}
		}
		//block mutation
		for(int block=0; block < Constants.NUMBER_OF_BLOCKS; block++)
		{
			for(int blockIndex=0; blockIndex < Constants.BLOCK_LENGTH; blockIndex++)
			{
				if(SeededRandom.getInstance().nextDouble() < Constants.BLOCK_MUTATION_RATE)
				{
					//Ensure we don't roll the same step again
					Step currentStep = blocks.get(block).get(blockIndex);
					List<Step> newSteps = new ArrayList<Step>();
					for(Step s : Step.validSteps)
					{
						if(!s.equals(currentStep))
						{
							newSteps.add(s);
						}
					}
					blocks.get(block).set(blockIndex, newSteps.get(SeededRandom.getInstance().nextInt(newSteps.size())));
				}
			}
		}
		
		//Refresh these values since they may have changed
		this.compileStrategy();
		this.fitness = fitnessFunction.getFitness(phenotype);
	}
	
	/**
	 * Compares fitness for sorting
	 */
	@Override
	public int compareTo(Agent other) {
		if(this.fitness > other.fitness)
		{
			return 1;
		}
		else if(this.fitness == other.fitness)
		{
			return 0;
		}
		else
		{
			return -1;
		}
	}
	
	//-------------------------------------------------------------------------------------------------------------------
	/**
	 * This area is for the different types of steps in the developmental program. These
	 * steps are called during the execution of executeSingleStep or executeStrategy.
	 * 
	 * These steps are only responsible for updating the value in phenotype. Saving previous
	 * phenotypes and updating the fitness is the responsibility of executeSingleStep
	 */
	
	/**
	 * Chooses a random neighbor of the current phenotype to be the new phenotype
	 */
	private void randomWalk()
	{
		List<Phenotype> neighbors = phenotype.getNeighbors();
		phenotype = neighbors.get(SeededRandom.getInstance().nextInt(neighbors.size()));
	}
	
	/**
	 * Chooses the highest fitness neighbor to be the new phenotype
	 */
	private void steepestClimb()
	{
		List<Phenotype> neighbors = phenotype.getNeighbors();
		Phenotype bestNeighbor = neighbors.get(0);
		for(Phenotype neighbor : neighbors)
		{
			if(fitnessFunction.getFitness(neighbor) > fitnessFunction.getFitness(bestNeighbor))
			{
				bestNeighbor = neighbor;
			}
		}
		phenotype = bestNeighbor;
	}
	
	/**
	 * Chooses the lowest fitness neighbor to be the new phenotype
	 */
	private void steepestFall()
	{
		List<Phenotype> neighbors = phenotype.getNeighbors();
		Phenotype worstNeighbor = neighbors.get(0);
		for(Phenotype neighbor : neighbors)
		{
			if(fitnessFunction.getFitness(neighbor) < fitnessFunction.getFitness(worstNeighbor))
			{
				worstNeighbor = neighbor;
			}
		}
		phenotype = worstNeighbor;
	}
	//-------------------------------------------------------------------------------------------------------------------
}
